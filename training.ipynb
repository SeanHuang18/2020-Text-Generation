{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Debug:\n",
    "    def __init__(self, debug_mode=True):\n",
    "        self.debug_mode = debug_mode\n",
    "        self.flag = {}\n",
    "\n",
    "    def log(self, target, flag=None):\n",
    "        if self.debug_mode:\n",
    "            if flag is None:\n",
    "                print(target)\n",
    "            else:\n",
    "                if flag in self.flag.keys():\n",
    "                    if self.flag[flag]:\n",
    "                        print(target)\n",
    "\n",
    "    def set_flag(self, flag: str, val: bool):\n",
    "        self.flag[flag] = val\n",
    "\n",
    "debug = Debug(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def token_check(target):\n",
    "    return target not in stopwords.words('english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class GeneratorExceptions(Exception):\n",
    "    \"\"\"\n",
    "    The Exception class for tracking all exceptions raised in data generator\n",
    "    Param\n",
    "        text: the displayed text\n",
    "    \"\"\"\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "\n",
    "class temp_generator:\n",
    "    def __init__(self, dataset_file_path : str=\"data/dataset/nysk.xml\", processed_dataset_path: str =\"data/processed_dataset/\"):\n",
    "        self.dataset_file_path = dataset_file_path\n",
    "        self.processed_dataset_path = processed_dataset_path\n",
    "        self.preprocess_data(override=False)\n",
    "\n",
    "    def preprocess_data(self, override=False):\n",
    "        if os.path.isfile(self.dataset_file_path):\n",
    "            if not os.path.isdir(self.processed_dataset_path):\n",
    "                os.mkdir(self.processed_dataset_path)\n",
    "\n",
    "            res = os.listdir(self.processed_dataset_path)\n",
    "\n",
    "            with open(self.dataset_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                doc = ET.ElementTree(file=f)\n",
    "\n",
    "            root = doc.getroot()\n",
    "            print(len(root))\n",
    "\n",
    "            for item in tqdm.tqdm(root):\n",
    "                news_id = item.findtext('docid')\n",
    "                source = item.findtext('source')\n",
    "                url = item.findtext('url')\n",
    "                title = item.findtext('title')\n",
    "                summary = item.findtext('summary')\n",
    "                text = item.findtext('text')\n",
    "\n",
    "                title = re.sub(r\"<.*>\", \"\", title)\n",
    "                title = re.sub(r\"\\W\", \"_\", title)\n",
    "                title = f\"{news_id}_{title[:10]}\"\n",
    "\n",
    "                fp = f\"{self.processed_dataset_path}{title}.txt\"\n",
    "                if not os.path.isfile(fp) or override:\n",
    "                    with open(fp, 'w', encoding='utf-8') as f:\n",
    "                        f.write(text)\n",
    "        else:\n",
    "            raise GeneratorExceptions(\"Path doesn't exist\")\n",
    "    \n",
    "    def get_one(self):\n",
    "        f_list = os.listdir(self.processed_dataset_path)\n",
    "        with open(f\"{self.processed_dataset_path}/{f_list[0]}\", 'r') as f:\n",
    "            text = f.read()\n",
    "            res = tokenize.sent_tokenize(text)\n",
    "        if debug.debug_mode:\n",
    "            for i in res:\n",
    "                print(i)\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 10421/10421 [00:00<00:00, 22113.47it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "10421\n",
      "The Neique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel maid, a West African immigrant, has occupied the fourth-floor High Bridge pad with her 15-year-old daughter since January -- and before that, lived in another Bronx apartment set aside by Harlem Community AIDS United strictly for adults with the virus and their families.\n",
      "The paper was unable to confirm if the accuser has HIV or AIDS because of medical confidentiality laws, but the Post confirmed that the agency rents apartments only for adults with the disease.\n",
      "A Harlem United employee said at least one adult in the apartment must be HIV-positive or have AIDS to qualify to live in one of the residences.\n",
      "Sources told the Post that only the alleged victim and her child lived in the apartment.\n",
      "Strauss-Kahn is accused of forcing the woman to perform oral sex on him.\n",
      "She told police that after the forced act, she spit his semen onto the floor.\n",
      "According to the federal Centers for Disease Control : \"It is possible for either partner to become infected with HIV through performing or receiving oral sex.\"\n",
      "Strauss-Kahn is on suicide watch at Rikers Island jail.\n",
      "Calls intensified for Strauss-Kahn to step down as head of the International Monetary Fund, with U.S. Treasury Secretary Timothy Geithner saying Strauss-Kahn \"is obviously not in a position to run\" the agency.\n",
      "Strauss-Kahn: Lasting Implications For IMF?\n",
      "FOLLOW HUFFPOST NEW YORK ON Facebook: Like 4 Twitter: Enter Email Address GET ALERTS CONTRIBUTE TO THIS STORY - Send Corrections - Send us a Link - Contact us - Send a Tip - Send Photos/Videos - Comment - Dominique Strauss-Kahn - New York Crime - NY News The New York Post has learned that the woman accusing IMF boss Dominique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel...\n",
      "The New York Post has learned that the woman accusing IMF boss Dominique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel... w York Post has learned that the woman accusing IMF boss Domin\n",
      "Number of samples: 14\n",
      "Number of unique input tokens: 61\n",
      "Number of unique output tokens: 61\n",
      "Max sequence length for inputs: 426\n",
      "Max sequence length for outputs: 426\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dg = temp_generator()\n",
    "sample_text = dg.get_one()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i in range(0, len(sample_text)-1):\n",
    "    input_t = f\"\\t{sample_text[i]}\\n\"\n",
    "    target_t = f\"\\t{sample_text[i+1]}\\n\"\n",
    "    input_texts.append(input_t)\n",
    "    target_texts.append(target_t)\n",
    "    \n",
    "    for c in input_t:\n",
    "        if c not in input_characters:\n",
    "            input_characters.add(c)\n",
    "    \n",
    "    for c in target_t:\n",
    "        if c not in target_characters:\n",
    "            target_characters.add(c)\n",
    "\n",
    "input_char_list = sorted(list(input_characters))\n",
    "target_char_list = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_char_list)\n",
    "num_decoder_tokens = len(target_char_list)\n",
    "\n",
    "max_encoder_sequence_len = max([len(t) for t in input_texts])\n",
    "max_decoder_sequence_len = max([len(t) for t in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_sequence_len)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_sequence_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]]\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_sequence_len, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_sequence_len, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_sequence_len, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "            decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "            decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print(encoder_input_data)\n",
    "print(decoder_target_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "batch_size = 64  \n",
    "epochs = 100  \n",
    "latent_dim = 256  \n",
    "num_samples = 10000\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 325632      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  325632      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 61)     15677       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 666,941\n",
      "Trainable params: 666,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_name = \"Model\\SeqToSeq_Model\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train on 11 samples, validate on 3 samples\n",
      "11/11 [==============================] - 6s 572ms/sample - loss: 5.3788 - accuracy: 0.0023 - val_loss: 4.0263 - val_accuracy: 0.8271\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1f82e160fc8>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    validation_split=0.2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 325632      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  325632      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 61)     15677       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 666,941\n",
      "Trainable params: 666,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights(\"Model/test.weights.hdf5\")\n",
    "# keras.models.save_model(model, model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_sequence_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 325632      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  325632      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 61)     15677       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 666,941\n",
      "Trainable params: 666,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "new_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "new_model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "new_model.load_weights(\"Model/test.weights.hdf5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "encoder_inputs = new_model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = new_model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = new_model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = new_model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = new_model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n",
      "-\n",
      "Input sentence: \tThe Neique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "1\n",
      "-\n",
      "Input sentence: \tFrom the Post: The hotel maid, a West African immigrant, has occupied the fourth-floor High Bridge pad with her 15-year-old daughter since January -- and before that, lived in another Bronx apartment set aside by Harlem Community AIDS United strictly for adults with the virus and their families.\n",
      "\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "2\n",
      "-\n",
      "Input sentence: \tThe paper was unable to confirm if the accuser has HIV or AIDS because of medical confidentiality laws, but the Post confirmed that the agency rents apartments only for adults with the disease.\n",
      "\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "3\n",
      "-\n",
      "Input sentence: \tA Harlem United employee said at least one adult in the apartment must be HIV-positive or have AIDS to qualify to live in one of the residences.\n",
      "\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "4\n",
      "-\n",
      "Input sentence: \tSources told the Post that only the alleged victim and her child lived in the apartment.\n",
      "\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                                                                                                                                            \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for seq_index in range(5):\n",
    "    print(seq_index)\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}