{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Debug:\n",
    "    def __init__(self, debug_mode=True):\n",
    "        self.debug_mode = debug_mode\n",
    "        self.flag = {}\n",
    "\n",
    "    def log(self, target, flag=None):\n",
    "        if self.debug_mode:\n",
    "            if flag is None:\n",
    "                print(target)\n",
    "            else:\n",
    "                if flag in self.flag.keys():\n",
    "                    if self.flag[flag]:\n",
    "                        print(target)\n",
    "\n",
    "    def set_flag(self, flag: str, val: bool):\n",
    "        self.flag[flag] = val\n",
    "\n",
    "debug = Debug(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class GeneratorExceptions(Exception):\n",
    "    \"\"\"\n",
    "    The Exception class for tracking all exceptions raised in data generator\n",
    "    Param\n",
    "        text: the displayed text\n",
    "    \"\"\"\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "\n",
    "class temp_generator:\n",
    "    def __init__(self, dataset_file_path : str=\"data/dataset/nysk.xml\", processed_dataset_path: str =\"data/processed_dataset/\"):\n",
    "        self.dataset_file_path = dataset_file_path\n",
    "        self.processed_dataset_path = processed_dataset_path\n",
    "        self.preprocess_data(override=False)\n",
    "\n",
    "    def preprocess_data(self, override=False):\n",
    "        if os.path.isfile(self.dataset_file_path):\n",
    "            if not os.path.isdir(self.processed_dataset_path):\n",
    "                os.mkdir(self.processed_dataset_path)\n",
    "\n",
    "            res = os.listdir(self.processed_dataset_path)\n",
    "\n",
    "            with open(self.dataset_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                doc = ET.ElementTree(file=f)\n",
    "\n",
    "            root = doc.getroot()\n",
    "            print(len(root))\n",
    "\n",
    "            for item in tqdm.tqdm(root):\n",
    "                news_id = item.findtext('docid')\n",
    "                source = item.findtext('source')\n",
    "                url = item.findtext('url')\n",
    "                title = item.findtext('title')\n",
    "                summary = item.findtext('summary')\n",
    "                text = item.findtext('text')\n",
    "\n",
    "                title = re.sub(r\"<.*>\", \"\", title)\n",
    "                title = re.sub(r\"\\W\", \"_\", title)\n",
    "                title = f\"{news_id}_{title[:10]}\"\n",
    "\n",
    "                fp = f\"{self.processed_dataset_path}{title}.txt\"\n",
    "                if not os.path.isfile(fp) or override:\n",
    "                    with open(fp, 'w', encoding='utf-8') as f:\n",
    "                        f.write(text)\n",
    "        else:\n",
    "            raise GeneratorExceptions(\"Path doesn't exist\")\n",
    "    \n",
    "    def get_one(self):\n",
    "        f_list = os.listdir(self.processed_dataset_path)\n",
    "        with open(f\"{self.processed_dataset_path}/{f_list[0]}\", 'r') as f:\n",
    "            text = f.read()\n",
    "            res = tokenize.sent_tokenize(text)\n",
    "        if debug.debug_mode:\n",
    "            for i in res:\n",
    "                print(i)\n",
    "        return res\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def generate_model(num_encoder_tokens, num_decoder_tokens, latent_dim=256):\n",
    "      \n",
    "    encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs_, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "    \n",
    "    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 10421/10421 [00:02<00:00, 3666.78it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "10421\n",
      "The Neique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel maid, a West African immigrant, has occupied the fourth-floor High Bridge pad with her 15-year-old daughter since January -- and before that, lived in another Bronx apartment set aside by Harlem Community AIDS United strictly for adults with the virus and their families.\n",
      "The paper was unable to confirm if the accuser has HIV or AIDS because of medical confidentiality laws, but the Post confirmed that the agency rents apartments only for adults with the disease.\n",
      "A Harlem United employee said at least one adult in the apartment must be HIV-positive or have AIDS to qualify to live in one of the residences.\n",
      "Sources told the Post that only the alleged victim and her child lived in the apartment.\n",
      "Strauss-Kahn is accused of forcing the woman to perform oral sex on him.\n",
      "She told police that after the forced act, she spit his semen onto the floor.\n",
      "According to the federal Centers for Disease Control : \"It is possible for either partner to become infected with HIV through performing or receiving oral sex.\"\n",
      "Strauss-Kahn is on suicide watch at Rikers Island jail.\n",
      "Calls intensified for Strauss-Kahn to step down as head of the International Monetary Fund, with U.S. Treasury Secretary Timothy Geithner saying Strauss-Kahn \"is obviously not in a position to run\" the agency.\n",
      "Strauss-Kahn: Lasting Implications For IMF?\n",
      "FOLLOW HUFFPOST NEW YORK ON Facebook: Like 4 Twitter: Enter Email Address GET ALERTS CONTRIBUTE TO THIS STORY - Send Corrections - Send us a Link - Contact us - Send a Tip - Send Photos/Videos - Comment - Dominique Strauss-Kahn - New York Crime - NY News The New York Post has learned that the woman accusing IMF boss Dominique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel...\n",
      "The New York Post has learned that the woman accusing IMF boss Dominique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "From the Post: The hotel... w York Post has learned that the woman accusing IMF boss Domin\n",
      "Number of samples: 14\n",
      "Number of unique input tokens: 61\n",
      "Number of unique output tokens: 61\n",
      "Max sequence length for inputs: 426\n",
      "Max sequence length for outputs: 426\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: put this into actual data generator\n",
    "dg = temp_generator()\n",
    "sample_text = dg.get_one()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for i in range(0, len(sample_text)-1):\n",
    "    input_t = f\"\\t{sample_text[i]}\\n\"\n",
    "    target_t = f\"\\t{sample_text[i+1]}\\n\"\n",
    "    input_texts.append(input_t)\n",
    "    target_texts.append(target_t)\n",
    "    \n",
    "    for c in input_t:\n",
    "        if c not in input_characters:\n",
    "            input_characters.add(c)\n",
    "    \n",
    "    for c in target_t:\n",
    "        if c not in target_characters:\n",
    "            target_characters.add(c)\n",
    "\n",
    "input_char_list = sorted(list(input_characters))\n",
    "target_char_list = sorted(list(target_characters))\n",
    "\n",
    "encoder_tokens_count = len(input_char_list)\n",
    "decoder_tokens_count = len(target_char_list)\n",
    "\n",
    "max_encoder_sequence_len = max([len(t) for t in input_texts])\n",
    "max_decoder_sequence_len = max([len(t) for t in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", encoder_tokens_count)\n",
    "print(\"Number of unique output tokens:\", decoder_tokens_count)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_sequence_len)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_sequence_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "[[[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_sequence_len, encoder_tokens_count), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_sequence_len, decoder_tokens_count), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_sequence_len, decoder_tokens_count), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "            decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "            decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print(encoder_input_data)\n",
    "print(decoder_target_data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "model = generate_model(num_encoder_tokens=encoder_tokens_count, \n",
    "                       num_decoder_tokens=decoder_tokens_count,\n",
    "                       latent_dim=latent_dim)\n",
    "\n",
    "model_name = \"Model\\SeqToSeq_Model\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train on 11 samples, validate on 3 samples\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 9s 804ms/sample - loss: 5.4639 - accuracy: 0.0017 - val_loss: 4.3245 - val_accuracy: 0.8286\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 2s 154ms/sample - loss: 4.8360 - accuracy: 0.7132 - val_loss: 1.3997 - val_accuracy: 0.8286\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 2s 154ms/sample - loss: 2.0284 - accuracy: 0.7132 - val_loss: 1.4420 - val_accuracy: 0.8286\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 2s 164ms/sample - loss: 2.3894 - accuracy: 0.7132 - val_loss: 1.2309 - val_accuracy: 0.8286\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 2s 163ms/sample - loss: 1.8608 - accuracy: 0.7132 - val_loss: 1.2031 - val_accuracy: 0.8286\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 189ms/sample - loss: 1.8224 - accuracy: 0.7132 - val_loss: 1.2044 - val_accuracy: 0.8286\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 203ms/sample - loss: 1.8024 - accuracy: 0.7132 - val_loss: 1.1705 - val_accuracy: 0.8286\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 236ms/sample - loss: 1.7926 - accuracy: 0.7132 - val_loss: 1.2347 - val_accuracy: 0.8286\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 238ms/sample - loss: 1.7993 - accuracy: 0.7132 - val_loss: 1.1543 - val_accuracy: 0.8286\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 238ms/sample - loss: 1.8388 - accuracy: 0.7132 - val_loss: 1.2577 - val_accuracy: 0.8286\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 247ms/sample - loss: 1.8088 - accuracy: 0.7132 - val_loss: 1.1419 - val_accuracy: 0.8286\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 3s 238ms/sample - loss: 1.8087 - accuracy: 0.7132 - val_loss: 1.2009 - val_accuracy: 0.8286\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 239ms/sample - loss: 1.7729 - accuracy: 0.7132 - val_loss: 1.1346 - val_accuracy: 0.8286\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 230ms/sample - loss: 1.7649 - accuracy: 0.7132 - val_loss: 1.1742 - val_accuracy: 0.8286\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 235ms/sample - loss: 1.7554 - accuracy: 0.7132 - val_loss: 1.1241 - val_accuracy: 0.8286\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 3s 239ms/sample - loss: 1.7489 - accuracy: 0.7132 - val_loss: 1.1699 - val_accuracy: 0.8286\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 2s 227ms/sample - loss: 1.7473 - accuracy: 0.7132 - val_loss: 1.1085 - val_accuracy: 0.8286\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 3s 234ms/sample - loss: 1.7511 - accuracy: 0.7132 - val_loss: 1.1807 - val_accuracy: 0.8286\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 3s 240ms/sample - loss: 1.7471 - accuracy: 0.7132 - val_loss: 1.0965 - val_accuracy: 0.8286\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 245ms/sample - loss: 1.7582 - accuracy: 0.7132 - val_loss: 1.1832 - val_accuracy: 0.8286\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 253ms/sample - loss: 1.7448 - accuracy: 0.7132 - val_loss: 1.0868 - val_accuracy: 0.8286\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 3s 246ms/sample - loss: 1.7477 - accuracy: 0.7132 - val_loss: 1.1621 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 250ms/sample - loss: 1.7292 - accuracy: 0.7132 - val_loss: 1.0754 - val_accuracy: 0.8286\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 3s 249ms/sample - loss: 1.7288 - accuracy: 0.7132 - val_loss: 1.1441 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 3s 252ms/sample - loss: 1.7176 - accuracy: 0.7132 - val_loss: 1.0666 - val_accuracy: 0.8286\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 250ms/sample - loss: 1.7186 - accuracy: 0.7132 - val_loss: 1.1394 - val_accuracy: 0.8286\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 3s 271ms/sample - loss: 1.7124 - accuracy: 0.7143 - val_loss: 1.0581 - val_accuracy: 0.8286\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 296ms/sample - loss: 1.7187 - accuracy: 0.7132 - val_loss: 1.1388 - val_accuracy: 0.8286\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 3s 270ms/sample - loss: 1.7109 - accuracy: 0.7143 - val_loss: 1.0542 - val_accuracy: 0.8286\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 3s 270ms/sample - loss: 1.7180 - accuracy: 0.7132 - val_loss: 1.1331 - val_accuracy: 0.8286\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 3s 287ms/sample - loss: 1.7067 - accuracy: 0.7143 - val_loss: 1.0514 - val_accuracy: 0.8286\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 3s 282ms/sample - loss: 1.7096 - accuracy: 0.7132 - val_loss: 1.1250 - val_accuracy: 0.8286\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 3s 269ms/sample - loss: 1.7011 - accuracy: 0.7143 - val_loss: 1.0470 - val_accuracy: 0.8286\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 3s 280ms/sample - loss: 1.7043 - accuracy: 0.7132 - val_loss: 1.1180 - val_accuracy: 0.8286\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 274ms/sample - loss: 1.6964 - accuracy: 0.7143 - val_loss: 1.0475 - val_accuracy: 0.8286\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 264ms/sample - loss: 1.6983 - accuracy: 0.7132 - val_loss: 1.1183 - val_accuracy: 0.8286\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 3s 244ms/sample - loss: 1.6948 - accuracy: 0.7143 - val_loss: 1.0412 - val_accuracy: 0.8286\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 3s 248ms/sample - loss: 1.6994 - accuracy: 0.7132 - val_loss: 1.1197 - val_accuracy: 0.8286\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 3s 261ms/sample - loss: 1.6935 - accuracy: 0.7143 - val_loss: 1.0402 - val_accuracy: 0.8286\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 3s 292ms/sample - loss: 1.6973 - accuracy: 0.7143 - val_loss: 1.1179 - val_accuracy: 0.8286\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 3s 245ms/sample - loss: 1.6925 - accuracy: 0.7143 - val_loss: 1.0444 - val_accuracy: 0.8286\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 3s 249ms/sample - loss: 1.6964 - accuracy: 0.7132 - val_loss: 1.1112 - val_accuracy: 0.8286\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 3s 280ms/sample - loss: 1.6896 - accuracy: 0.7143 - val_loss: 1.0409 - val_accuracy: 0.8286\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 3s 263ms/sample - loss: 1.6868 - accuracy: 0.7132 - val_loss: 1.1078 - val_accuracy: 0.8286\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 4s 336ms/sample - loss: 1.6831 - accuracy: 0.7143 - val_loss: 1.0341 - val_accuracy: 0.8286\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 3s 302ms/sample - loss: 1.6872 - accuracy: 0.7143 - val_loss: 1.1143 - val_accuracy: 0.8286\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 3s 279ms/sample - loss: 1.6824 - accuracy: 0.7143 - val_loss: 1.0308 - val_accuracy: 0.8286\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 3s 272ms/sample - loss: 1.6889 - accuracy: 0.7143 - val_loss: 1.1119 - val_accuracy: 0.8286\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 3s 272ms/sample - loss: 1.6811 - accuracy: 0.7143 - val_loss: 1.0340 - val_accuracy: 0.8286\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 3s 265ms/sample - loss: 1.6836 - accuracy: 0.7143 - val_loss: 1.1180 - val_accuracy: 0.8286\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 3s 277ms/sample - loss: 1.6807 - accuracy: 0.7143 - val_loss: 1.0283 - val_accuracy: 0.8286\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 3s 262ms/sample - loss: 1.7211 - accuracy: 0.7132 - val_loss: 1.1253 - val_accuracy: 0.8286\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 3s 282ms/sample - loss: 1.6869 - accuracy: 0.7143 - val_loss: 1.0302 - val_accuracy: 0.8286\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 3s 259ms/sample - loss: 1.6813 - accuracy: 0.7143 - val_loss: 1.1050 - val_accuracy: 0.8286\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 3s 262ms/sample - loss: 1.6729 - accuracy: 0.7143 - val_loss: 1.0375 - val_accuracy: 0.8286\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 3s 241ms/sample - loss: 1.6760 - accuracy: 0.7143 - val_loss: 1.0869 - val_accuracy: 0.8286\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 3s 242ms/sample - loss: 1.6664 - accuracy: 0.7143 - val_loss: 1.0387 - val_accuracy: 0.8286\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 3s 284ms/sample - loss: 1.6573 - accuracy: 0.7143 - val_loss: 1.0865 - val_accuracy: 0.8286\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 3s 251ms/sample - loss: 1.6784 - accuracy: 0.7128 - val_loss: 1.1201 - val_accuracy: 0.8286\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 3s 254ms/sample - loss: 1.6724 - accuracy: 0.7134 - val_loss: 1.0403 - val_accuracy: 0.8286\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 3s 276ms/sample - loss: 1.6854 - accuracy: 0.7134 - val_loss: 1.2417 - val_accuracy: 0.8286\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 3s 267ms/sample - loss: 1.7098 - accuracy: 0.7132 - val_loss: 1.0201 - val_accuracy: 0.8286\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 3s 284ms/sample - loss: 1.7338 - accuracy: 0.7132 - val_loss: 1.1546 - val_accuracy: 0.8286\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 3s 274ms/sample - loss: 1.6793 - accuracy: 0.7136 - val_loss: 1.0439 - val_accuracy: 0.8286\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 3s 273ms/sample - loss: 1.6452 - accuracy: 0.7143 - val_loss: 1.1131 - val_accuracy: 0.8286\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 3s 261ms/sample - loss: 1.8208 - accuracy: 0.7132 - val_loss: 1.2348 - val_accuracy: 0.8286\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 3s 270ms/sample - loss: 1.7615 - accuracy: 0.7132 - val_loss: 1.1155 - val_accuracy: 0.8294\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 3s 307ms/sample - loss: 1.7473 - accuracy: 0.7134 - val_loss: 1.1827 - val_accuracy: 0.8294\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 3s 246ms/sample - loss: 1.7201 - accuracy: 0.7134 - val_loss: 1.1284 - val_accuracy: 0.8294\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 3s 261ms/sample - loss: 1.6978 - accuracy: 0.7134 - val_loss: 1.1373 - val_accuracy: 0.8294\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 3s 250ms/sample - loss: 1.6850 - accuracy: 0.7134 - val_loss: 1.2434 - val_accuracy: 0.8294\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 3s 247ms/sample - loss: 1.7740 - accuracy: 0.7134 - val_loss: 1.1105 - val_accuracy: 0.8294\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 3s 245ms/sample - loss: 1.8167 - accuracy: 0.7134 - val_loss: 1.1915 - val_accuracy: 0.8294\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 3s 250ms/sample - loss: 1.7337 - accuracy: 0.7134 - val_loss: 1.1145 - val_accuracy: 0.8294\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 3s 247ms/sample - loss: 1.7190 - accuracy: 0.7134 - val_loss: 1.1534 - val_accuracy: 0.8294\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 3s 267ms/sample - loss: 1.7094 - accuracy: 0.7134 - val_loss: 1.1207 - val_accuracy: 0.8294\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 3s 273ms/sample - loss: 1.7028 - accuracy: 0.7134 - val_loss: 1.1458 - val_accuracy: 0.8294\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 3s 278ms/sample - loss: 1.6961 - accuracy: 0.7134 - val_loss: 1.1061 - val_accuracy: 0.8294\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 3s 266ms/sample - loss: 1.6909 - accuracy: 0.7134 - val_loss: 1.2098 - val_accuracy: 0.8294\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 3s 254ms/sample - loss: 1.7199 - accuracy: 0.7134 - val_loss: 1.0893 - val_accuracy: 0.8294\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 3s 280ms/sample - loss: 1.7790 - accuracy: 0.7134 - val_loss: 1.1981 - val_accuracy: 0.8294\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 3s 301ms/sample - loss: 1.7154 - accuracy: 0.7134 - val_loss: 1.0939 - val_accuracy: 0.8294\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 3s 240ms/sample - loss: 1.6944 - accuracy: 0.7134 - val_loss: 1.1465 - val_accuracy: 0.8294\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 3s 250ms/sample - loss: 1.6807 - accuracy: 0.7134 - val_loss: 1.0657 - val_accuracy: 0.8286\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 3s 263ms/sample - loss: 1.6908 - accuracy: 0.7132 - val_loss: 1.1358 - val_accuracy: 0.8286\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 3s 255ms/sample - loss: 1.6955 - accuracy: 0.7130 - val_loss: 1.0709 - val_accuracy: 0.8286\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 3s 274ms/sample - loss: 1.6697 - accuracy: 0.7132 - val_loss: 1.1597 - val_accuracy: 0.8294\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 3s 252ms/sample - loss: 1.6604 - accuracy: 0.7134 - val_loss: 1.0466 - val_accuracy: 0.8294\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 3s 283ms/sample - loss: 1.6766 - accuracy: 0.7134 - val_loss: 1.1681 - val_accuracy: 0.8294\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 3s 256ms/sample - loss: 1.6636 - accuracy: 0.7134 - val_loss: 1.0523 - val_accuracy: 0.8294\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 3s 247ms/sample - loss: 1.6675 - accuracy: 0.7134 - val_loss: 1.1287 - val_accuracy: 0.8294\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 3s 252ms/sample - loss: 1.6388 - accuracy: 0.7134 - val_loss: 1.0457 - val_accuracy: 0.8294\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 3s 265ms/sample - loss: 1.6463 - accuracy: 0.7134 - val_loss: 1.1427 - val_accuracy: 0.8294\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 3s 249ms/sample - loss: 1.6447 - accuracy: 0.7134 - val_loss: 1.0339 - val_accuracy: 0.8294\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 3s 260ms/sample - loss: 1.6454 - accuracy: 0.7134 - val_loss: 1.1528 - val_accuracy: 0.8294\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 3s 268ms/sample - loss: 1.6514 - accuracy: 0.7134 - val_loss: 1.0422 - val_accuracy: 0.8294\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 3s 256ms/sample - loss: 1.6679 - accuracy: 0.7134 - val_loss: 1.1173 - val_accuracy: 0.8294\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 3s 257ms/sample - loss: 1.6295 - accuracy: 0.7134 - val_loss: 1.0283 - val_accuracy: 0.8294\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 3s 258ms/sample - loss: 1.6192 - accuracy: 0.7145 - val_loss: 1.0881 - val_accuracy: 0.8294\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 3s 253ms/sample - loss: 1.6047 - accuracy: 0.7145 - val_loss: 1.0193 - val_accuracy: 0.8294\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x18781b4de88>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "batch_size = 64  \n",
    "epochs = 1  \n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 325632      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  325632      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 61)     15677       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 666,941\n",
      "Trainable params: 666,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model.save_weights(\"Model/test.weights.hdf5\")\n",
    "# keras.models.save_model(model, model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, decoder_tokens_count))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_sequence_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, decoder_tokens_count))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 325632      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  325632      input_4[0][0]                    \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 61)     15677       lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 666,941\n",
      "Trainable params: 666,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "new_model = generate_model(num_encoder_tokens=encoder_tokens_count, \n",
    "                           num_decoder_tokens=decoder_tokens_count,\n",
    "                           latent_dim=latent_dim)\n",
    "new_model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "new_model.load_weights(\"Model/test.weights.hdf5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "encoder_inputs = new_model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = new_model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = new_model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_6\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_7\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = new_model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = new_model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n",
      "-\n",
      "Input sentence: \tThe Neique Strauss-Kahn of sexual assault lived in an apartment exclusively for patients with HIV and AIDS.\n",
      "\n",
      "Decoded sentence: F                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "1\n",
      "-\n",
      "Input sentence: \tFrom the Post: The hotel maid, a West African immigrant, has occupied the fourth-floor High Bridge pad with her 15-year-old daughter since January -- and before that, lived in another Bronx apartment set aside by Harlem Community AIDS United strictly for adults with the virus and their families.\n",
      "\n",
      "Decoded sentence: S                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "2\n",
      "-\n",
      "Input sentence: \tThe paper was unable to confirm if the accuser has HIV or AIDS because of medical confidentiality laws, but the Post confirmed that the agency rents apartments only for adults with the disease.\n",
      "\n",
      "Decoded sentence: S                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "3\n",
      "-\n",
      "Input sentence: \tA Harlem United employee said at least one adult in the apartment must be HIV-positive or have AIDS to qualify to live in one of the residences.\n",
      "\n",
      "Decoded sentence: S                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "4\n",
      "-\n",
      "Input sentence: \tSources told the Post that only the alleged victim and her child lived in the apartment.\n",
      "\n",
      "Decoded sentence: S                                                                                                                                                                                                                                                                                                                                                                                                                                          \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for seq_index in range(5):\n",
    "    print(seq_index)\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}